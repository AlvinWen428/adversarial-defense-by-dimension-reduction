{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import deque\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from locally_linear import LocallyLinearBackward\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from model.vgg_tiny import Conv, Fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "memory_gpu=[int(x.split()[2]) for x in open('tmp','r').readlines()]\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=str(np.argmax(memory_gpu))\n",
    "os.system('rm tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCH = 100\n",
    "n_dimentions = 32\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isomap(feature_queue, n_components):\n",
    "    length = len(feature_queue)\n",
    "    for i in range(length):\n",
    "        if i == 0:\n",
    "            feature_tmp = feature_queue.popleft()\n",
    "            features = feature_tmp\n",
    "            feature_to_use = feature_tmp\n",
    "        else:\n",
    "            feature_tmp = feature_queue.popleft()\n",
    "            features = np.concatenate((features, feature_tmp), axis=0)\n",
    "    \n",
    "#     np.save('x.npy', features)\n",
    "#     np.save('x_50.npy', feature_to_use)\n",
    "    feature_input = features\n",
    "    embedding = Isomap(n_components=n_components)\n",
    "    transformed = embedding.fit_transform(feature_input)\n",
    "    \n",
    "#     np.save('y.npy', transformed)\n",
    "    return transformed, feature_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isomap_back(X_Que,Y_use,Y_all,Error):\n",
    "#Error has dim:p*N, where p is the dims of every object after isomap N is the batchsize\n",
    "#Y is the feature during the forward process\n",
    "#X is the feature before Isomap\n",
    "\n",
    "    k=4\n",
    "    E=Error.cpu().numpy()\n",
    "    Y_use = Y_use.detach().cpu().numpy()\n",
    "    length=len(X_Que)\n",
    "    for i in range(length):\n",
    "        if i == 0:\n",
    "            feature_tmp = X_Que.popleft()\n",
    "            X_use=feature_tmp\n",
    "            X = feature_tmp\n",
    "        else:\n",
    "            feature_tmp = X_Que.popleft()\n",
    "            X = np.concatenate((X, feature_tmp), axis=0)\n",
    "#     np.save('Y_50.npy', Y_use)\n",
    "    Yb=Y_use+E\n",
    "#     np.save('Y_hat_50.npy', Yb)\n",
    "#Calculate all the distances between Yb and all Y\n",
    "    n=Yb.shape\n",
    "    total=Y_all.shape\n",
    "    for i in range(n[0]):\n",
    "        dis=np.zeros(total[0])\n",
    "        Yi=Yb[i]\n",
    "        for j in range(total[0]):\n",
    "            z=(Yi-Y_all[j]).reshape(-1,1)\n",
    "            dis[j]=np.matmul(z.transpose(),z)\n",
    "        idx = np.argpartition(dis, k)[0:k]\n",
    "        for m in range(k):\n",
    "            if m==0:\n",
    "                Y_near=Y_all[idx[m]].reshape([1,-1])\n",
    "                X_near = X[idx[m]].reshape([1,-1])\n",
    "                Y_bar=Yi.reshape([1,-1])\n",
    "            else:\n",
    "                Y_near=np.concatenate((Y_near,Y_all[idx[m]].reshape([1,-1])),axis=0)\n",
    "                X_near=np.concatenate((X_near,X[idx[m]].reshape([1,-1])),axis=0)\n",
    "                Y_bar=np.concatenate((Y_bar,Yi.reshape([1,-1])),axis=0)\n",
    "        Y_all_hat = np.concatenate((Yb, Y_all[BATCH_SIZE:]), axis=0)\n",
    "#         np.save('Y_all_hat.npy', Y_all_hat)\n",
    "        tmp=np.mat(Y_bar-Y_near)\n",
    "        Z=tmp*tmp.transpose()\n",
    "        One=np.mat(np.ones([k, 1]))\n",
    "        X_near=np.mat(X_near)\n",
    "        w=(np.linalg.pinv(Z))*One/(One.transpose()*(np.linalg.pinv(Z))*One)\n",
    "        if i==0:\n",
    "            X_back=(X_near.transpose()*w).reshape([1,-1])\n",
    "        else:\n",
    "            X_back=np.concatenate((X_back,(X_near.transpose()*w).reshape([1,-1])),axis=0)\n",
    "    return X_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(28),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "data_train = dsets.MNIST(root = \"./data/\",\n",
    "                         transform=transform,\n",
    "                            train = True,\n",
    "                            download = True)\n",
    "\n",
    "data_test = dsets.MNIST(root=\"./data/\",\n",
    "                        transform=transform,\n",
    "                           train = False)\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(dataset=data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(dataset=data_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATA4_DB3/data/wen/isomap/workspace/model/vgg_tiny.py:85: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  m.weight = nn.init.xavier_normal(m.weight)\n"
     ]
    }
   ],
   "source": [
    "vgg_conv = Conv().to(device)\n",
    "vgg_fc = Fc(input_channel=32, output_channel=10).to(device)\n",
    "\n",
    "vgg_conv.load_state_dict(torch.load('./model_saved/conv_train_isomap_pureconv_SGD_downdimension_50_isomap_number_5000_neighbors_7_epoch_19.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isomap_feature = torch.empty(BATCH_SIZE, n_dimentions, requires_grad=True, device=device)\n",
    "cost1 = tnn.MSELoss()\n",
    "cost2 = tnn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.SGD(vgg_conv.parameters(), lr=LEARNING_RATE)\n",
    "optimizer2 = torch.optim.SGD(vgg_fc.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/100  batch:19/1200  loss1:28.391253  loss2:2.077398  acc:0.3200\n",
      "epoch:0/100  batch:20/1200  loss1:14.478447  loss2:2.128017  acc:0.3400\n",
      "epoch:0/100  batch:21/1200  loss1:22.887938  loss2:2.237112  acc:0.0800\n",
      "epoch:0/100  batch:22/1200  loss1:22.837029  loss2:2.230905  acc:0.1800\n",
      "epoch:0/100  batch:23/1200  loss1:16.240427  loss2:2.212875  acc:0.2000\n",
      "epoch:0/100  batch:24/1200  loss1:24.894207  loss2:2.190921  acc:0.1800\n",
      "epoch:0/100  batch:25/1200  loss1:27.551456  loss2:2.274787  acc:0.1400\n",
      "epoch:0/100  batch:26/1200  loss1:19.819288  loss2:2.104362  acc:0.2800\n",
      "epoch:0/100  batch:27/1200  loss1:20.001667  loss2:2.206808  acc:0.1000\n",
      "epoch:0/100  batch:28/1200  loss1:23.060469  loss2:2.223445  acc:0.1200\n",
      "epoch:0/100  batch:29/1200  loss1:23.352383  loss2:2.214193  acc:0.1200\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(EPOCH):\n",
    "#  for i, (images, labels) in enumerate(trainLoader):\n",
    "  vgg_conv.train()\n",
    "  vgg_fc.train()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  train_img_queue = deque(maxlen=1000//BATCH_SIZE)    #构建输入图像的队列\n",
    "  train_label_queue = deque(maxlen=1000//BATCH_SIZE) #构建label的队列\n",
    "  train_vec_queue = deque(maxlen=1000//BATCH_SIZE)    #构建卷积网络输出向量的队列\n",
    "  for batch_idx, (images, labels) in enumerate(trainLoader):\n",
    "    train_img_queue.append(images)   #入队是append，出队是popleft\n",
    "    train_label_queue.append(labels)\n",
    "    \n",
    "    # Forward + Backward + Optimize\n",
    "    \n",
    "#     optimizer1.zero_grad()\n",
    "#     optimizer2.zero_grad()\n",
    "\n",
    "    outputs1 = vgg_conv(images.to(device)) #卷积网络的输出，将图片embedding成512维向量，the shape of output is (batch_size, 512)\n",
    "    #print(images, outputs1)\n",
    "    train_vec_queue.append(outputs1.detach().cpu().numpy())\n",
    "#     print(train_vec_queue.qsize())\n",
    "#     print(train_vec_queue.get_nowait().shape)\n",
    "    \n",
    "    if len(train_img_queue) == 1000//BATCH_SIZE:  #等队列满了之后，开始让所有图片进入isomap，然后pop出队首的数据进行反向传播\n",
    "        isomap_forward, feature_to_use = isomap(copy.deepcopy(train_vec_queue), n_components=32)#将1000张图片通过卷积层得到的embedding向量输入isomap层，获得降维后的结果\n",
    "        #isomap: numpy.ndarray   feature_to_use: numpy.ndarray\n",
    "        \n",
    "        train_label_tmp = copy.deepcopy(train_label_queue)\n",
    "        for i in range(len(train_label_tmp)):\n",
    "            if i == 0:\n",
    "                feature_tmp = train_label_tmp.popleft()\n",
    "                label_npy = feature_tmp\n",
    "            else:\n",
    "                feature_tmp = train_label_tmp.popleft()\n",
    "                label_npy = np.concatenate((label_npy, feature_tmp), axis=0)\n",
    "#         np.save('isomap_label.npy', label_npy)\n",
    "        \n",
    "        feature_to_use = torch.Tensor(feature_to_use)\n",
    "        if outputs1.is_cuda:\n",
    "            batch_feature = torch.from_numpy(isomap_forward[:BATCH_SIZE]).cuda()\n",
    "        else:\n",
    "            batch_feature = torch.from_numpy(isomap_forward[:BATCH_SIZE])\n",
    "        \n",
    "        batch_feature = batch_feature.float()\n",
    "        \n",
    "#         img_tmp = train_img_queue.popleft()\n",
    "#         label_tmp = train_label_queue.popleft()\n",
    "#         vec_tmp = train_vec_queue.popleft()\n",
    "        \n",
    "        isomap_feature = batch_feature\n",
    "        isomap_feature.requires_grad = True\n",
    "        outputs2 = vgg_fc(isomap_feature)\n",
    "        batch_label = train_label_queue.popleft()\n",
    "        loss2 = cost2(outputs2, batch_label.squeeze().to(device))\n",
    "        \n",
    "        #---------------------------------------\n",
    "        optimizer2.zero_grad()\n",
    "        loss2.backward()\n",
    "        optimizer2.step()\n",
    "        \n",
    "        grad = isomap_feature.grad\n",
    "        \n",
    "        E = grad*LEARNING_RATE\n",
    "        x_hat = isomap_back(copy.deepcopy(train_vec_queue), isomap_feature, isomap_forward, E)\n",
    "#         np.save('x_hat_50.npy', x_hat)\n",
    "        #all X:copy.deepcopy(train_vec_queue) Y:isomap_feature    all Y: isomap_forward     y error:E\n",
    "        x_hat = torch.Tensor(x_hat)\n",
    "        loss1 = cost1(feature_to_use.to(device), x_hat.to(device))\n",
    "        loss1.requires_grad = True\n",
    "        optimizer1.zero_grad()\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "        \n",
    "        train_vec_queue.popleft()\n",
    "        train_img_queue.popleft()\n",
    "        \n",
    "        pred = torch.max(outputs2.data, 1)[1]\n",
    "        train_correct = (pred == batch_label.to(device)).sum()\n",
    "        \n",
    "        print('epoch:{}/{}  batch:{}/{}  loss1:{:.6f}  loss2:{:.6f}  acc:{:.4f}'.format(epoch, EPOCH, batch_idx,\n",
    "                                                                         data_train.__len__() // BATCH_SIZE, loss1,\n",
    "                                                                         loss2, float(train_correct) / BATCH_SIZE))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
