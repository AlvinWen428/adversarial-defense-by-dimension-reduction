{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from collections import deque\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from locally_linear import LocallyLinearBackward\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from model.vgg_tiny import Conv, Fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "memory_gpu=[int(x.split()[2]) for x in open('tmp','r').readlines()]\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=str(np.argmax(memory_gpu))\n",
    "os.system('rm tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCH = 100\n",
    "n_dimentions = 7\n",
    "isomap_number = 1000\n",
    "write_log = True\n",
    "n_neighbors = 5\n",
    "\n",
    "embedding = Isomap(n_components=n_dimentions, n_neighbors=n_neighbors)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isomap(feature_queue, n_components):\n",
    "    length = len(feature_queue)\n",
    "    for i in range(length):\n",
    "        if i == 0:\n",
    "            feature_tmp = feature_queue.popleft()\n",
    "            features = feature_tmp\n",
    "            feature_to_use = feature_tmp\n",
    "        else:\n",
    "            feature_tmp = feature_queue.popleft()\n",
    "            features = np.concatenate((features, feature_tmp), axis=0)\n",
    "    \n",
    "#     np.save('x.npy', features)\n",
    "#     np.save('x_50.npy', feature_to_use)\n",
    "    feature_input = features\n",
    "#     embedding = Isomap(n_components=n_components)\n",
    "    transformed = embedding.fit_transform(feature_input)\n",
    "    \n",
    "#     np.save('y.npy', transformed)\n",
    "    return transformed, feature_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isomap_back(X_Que,Y_use,Y_all,Error):\n",
    "#Error has dim:p*N, where p is the dims of every object after isomap N is the batchsize\n",
    "#Y is the feature during the forward process\n",
    "#X is the feature before Isomap\n",
    "\n",
    "    k=4\n",
    "    E=Error.cpu().numpy()\n",
    "    Y_use = Y_use.detach().cpu().numpy()\n",
    "    length=len(X_Que)\n",
    "    for i in range(length):\n",
    "        if i == 0:\n",
    "            feature_tmp = X_Que.popleft()\n",
    "            X_use=feature_tmp\n",
    "            X = feature_tmp\n",
    "        else:\n",
    "            feature_tmp = X_Que.popleft()\n",
    "            X = np.concatenate((X, feature_tmp), axis=0)\n",
    "#     np.save('Y_50.npy', Y_use)\n",
    "    Yb=Y_use+E\n",
    "#     np.save('Y_hat_50.npy', Yb)\n",
    "#Calculate all the distances between Yb and all Y\n",
    "    n=Yb.shape\n",
    "    total=Y_all.shape\n",
    "    for i in range(n[0]):\n",
    "        dis=np.zeros(total[0])\n",
    "        Yi=Yb[i]\n",
    "        for j in range(total[0]):\n",
    "            z=(Yi-Y_all[j]).reshape(-1,1)\n",
    "            dis[j]=np.matmul(z.transpose(),z)\n",
    "        idx = np.argpartition(dis, k)[0:k]\n",
    "        for m in range(k):\n",
    "            if m==0:\n",
    "                Y_near=Y_all[idx[m]].reshape([1,-1])\n",
    "                X_near = X[idx[m]].reshape([1,-1])\n",
    "                Y_bar=Yi.reshape([1,-1])\n",
    "            else:\n",
    "                Y_near=np.concatenate((Y_near,Y_all[idx[m]].reshape([1,-1])),axis=0)\n",
    "                X_near=np.concatenate((X_near,X[idx[m]].reshape([1,-1])),axis=0)\n",
    "                Y_bar=np.concatenate((Y_bar,Yi.reshape([1,-1])),axis=0)\n",
    "        Y_all_hat = np.concatenate((Yb, Y_all[BATCH_SIZE:]), axis=0)\n",
    "#         np.save('Y_all_hat.npy', Y_all_hat)\n",
    "        tmp=np.mat(Y_bar-Y_near)\n",
    "        Z=tmp*tmp.transpose()\n",
    "        One=np.mat(np.ones([k, 1]))\n",
    "        X_near=np.mat(X_near)\n",
    "        w=(np.linalg.pinv(Z))*One/(One.transpose()*(np.linalg.pinv(Z))*One)\n",
    "        if i==0:\n",
    "            X_back=(X_near.transpose()*w).reshape([1,-1])\n",
    "        else:\n",
    "            X_back=np.concatenate((X_back,(X_near.transpose()*w).reshape([1,-1])),axis=0)\n",
    "    return X_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vgg_conv.train()\n",
    "    vgg_fc.train()\n",
    "    all_correct = 0\n",
    "    total = 0\n",
    "    train_img_queue = deque(maxlen=isomap_number//BATCH_SIZE)    #构建输入图像的队列\n",
    "    train_label_queue = deque(maxlen=isomap_number//BATCH_SIZE) #构建label的队列\n",
    "    train_vec_queue = deque(maxlen=isomap_number//BATCH_SIZE)    #构建卷积网络输出向量的队列\n",
    "    for batch_idx, (images, labels) in enumerate(tqdm(trainLoader)):\n",
    "        total += images.shape[0]\n",
    "        train_img_queue.append(images)   #入队是append，出队是popleft\n",
    "        train_label_queue.append(labels)\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "\n",
    "    #     optimizer1.zero_grad()\n",
    "    #     optimizer2.zero_grad()\n",
    "\n",
    "        outputs1 = vgg_conv(images.to(device)) #卷积网络的输出，将图片embedding成512维向量，the shape of output is (batch_size, 512)\n",
    "        #print(images, outputs1)\n",
    "        train_vec_queue.append(outputs1.detach().cpu().numpy())\n",
    "    #     print(train_vec_queue.qsize())\n",
    "    #     print(train_vec_queue.get_nowait().shape)\n",
    "\n",
    "        if len(train_img_queue) == isomap_number//BATCH_SIZE:  #等队列满了之后，开始让所有图片进入isomap，然后pop出队首的数据进行反向传播\n",
    "            isomap_forward, feature_to_use = isomap(copy.deepcopy(train_vec_queue), n_components=32)#将1000张图片通过卷积层得到的embedding向量输入isomap层，获得降维后的结果\n",
    "            #isomap: numpy.ndarray   feature_to_use: numpy.ndarray\n",
    "\n",
    "            train_label_tmp = copy.deepcopy(train_label_queue)\n",
    "            for i in range(len(train_label_tmp)):\n",
    "                if i == 0:\n",
    "                    feature_tmp = train_label_tmp.popleft()\n",
    "                    label_npy = feature_tmp\n",
    "                else:\n",
    "                    feature_tmp = train_label_tmp.popleft()\n",
    "                    label_npy = np.concatenate((label_npy, feature_tmp), axis=0)\n",
    "    #         np.save('isomap_label.npy', label_npy)\n",
    "\n",
    "            feature_to_use = torch.Tensor(feature_to_use)\n",
    "            if outputs1.is_cuda:\n",
    "                batch_feature = torch.from_numpy(isomap_forward[:BATCH_SIZE]).cuda()\n",
    "            else:\n",
    "                batch_feature = torch.from_numpy(isomap_forward[:BATCH_SIZE])\n",
    "\n",
    "            batch_feature = batch_feature.float()\n",
    "\n",
    "    #         img_tmp = train_img_queue.popleft()\n",
    "    #         label_tmp = train_label_queue.popleft()\n",
    "    #         vec_tmp = train_vec_queue.popleft()\n",
    "\n",
    "            isomap_feature = batch_feature\n",
    "            isomap_feature.requires_grad = True\n",
    "            outputs2 = vgg_fc(isomap_feature)\n",
    "            batch_label = train_label_queue.popleft()\n",
    "            loss2 = cost2(outputs2, batch_label.squeeze().to(device))\n",
    "\n",
    "            #---------------------------------------\n",
    "            optimizer2.zero_grad()\n",
    "            loss2.backward()\n",
    "            optimizer2.step()\n",
    "\n",
    "            grad = isomap_feature.grad\n",
    "\n",
    "            E = grad*LEARNING_RATE\n",
    "            x_hat = isomap_back(copy.deepcopy(train_vec_queue), isomap_feature, isomap_forward, E)\n",
    "    #         np.save('x_hat_50.npy', x_hat)\n",
    "            #all X:copy.deepcopy(train_vec_queue) Y:isomap_feature    all Y: isomap_forward     y error:E\n",
    "            x_hat = torch.Tensor(x_hat)\n",
    "            loss1 = cost1(feature_to_use.to(device), x_hat.to(device))\n",
    "            loss1.requires_grad = True\n",
    "            optimizer1.zero_grad()\n",
    "            loss1.backward()\n",
    "            optimizer1.step()\n",
    "\n",
    "            train_vec_queue.popleft()\n",
    "            train_img_queue.popleft()\n",
    "\n",
    "            pred = torch.max(outputs2.data, 1)[1]\n",
    "            train_correct = (pred == batch_label.to(device)).sum()\n",
    "            all_correct += train_correct\n",
    "\n",
    "            print('epoch:{}/{}  batch:{}/{}  loss1:{:.6f}  loss2:{:.6f}  acc:{:.4f} all_acc:{:.4f}'.format(epoch, EPOCH, batch_idx,\n",
    "                                                                             data_train.__len__() // BATCH_SIZE, loss1,\n",
    "                                                                             loss2, float(train_correct) / BATCH_SIZE,\n",
    "                                                                             float(all_correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    vgg_conv.eval()\n",
    "    vgg_fc.eval()\n",
    "    features_number = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(trainLoader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        features = vgg_conv(data)\n",
    "        if features_number == 0:\n",
    "            features_tensor = features.cpu().detach()\n",
    "            target_tensor = target\n",
    "            features_number += BATCH_SIZE\n",
    "        elif features_number < isomap_number - BATCH_SIZE:\n",
    "            features_tensor = torch.cat((features_tensor, features.cpu().detach()), dim=0)\n",
    "            target_tensor = torch.cat((target_tensor, target), dim=0)\n",
    "            features_number += BATCH_SIZE\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(testLoader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        features = vgg_conv(data)\n",
    "        features_array = torch.cat((features_tensor[:isomap_number - BATCH_SIZE], features.cpu().detach()),\n",
    "                                   dim=0).numpy()\n",
    "        target_tensor = target\n",
    "        if torch.cuda.is_available():\n",
    "            transformed = torch.Tensor(embedding.transform(features_array)[isomap_number - BATCH_SIZE:]).cuda()\n",
    "        else:\n",
    "            transformed = torch.Tensor(embedding.transform(features_array)[isomap_number - BATCH_SIZE:])\n",
    "        output = vgg_fc(transformed)\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target_tensor.data.view_as(pred)).cpu().sum()\n",
    "        total += target_tensor.shape[0]\n",
    "\n",
    "        loss = cost2(output, target_tensor.squeeze().to(device))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    log = ('Test Epoch: {}\\tAcc:[{}/{}]{:.6f} Loss: {:.6f}'.format(\n",
    "                epoch, int(correct), int(total), float(correct)/float(total)*100, total_loss))\n",
    "    print(log)\n",
    "    if write_log:\n",
    "        writer.add_scalar('Isomap_test_loss', total_loss, epoch)\n",
    "        writer.add_scalar('Isomap_test_accuracy', float(correct) / float(total) * 100, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "data_train = dsets.MNIST(root = \"./data/\",\n",
    "                         transform=transform,\n",
    "                            train = True,\n",
    "                            download = True)\n",
    "\n",
    "data_test = dsets.MNIST(root=\"./data/\",\n",
    "                        transform=transform,\n",
    "                           train = False)\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(dataset=data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(dataset=data_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATA4_DB3/data/wen/isomap/workspace/model/vgg_tiny.py:85: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  m.weight = nn.init.xavier_normal(m.weight)\n"
     ]
    }
   ],
   "source": [
    "vgg_conv = Conv().to(device)\n",
    "vgg_fc = Fc(input_channel=7, output_channel=10).to(device)\n",
    "\n",
    "vgg_conv.load_state_dict(torch.load('./model_saved/conv_train_isomap_pureconv_SGD_downdimension_50_isomap_number_5000_neighbors_7_epoch_19.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isomap_feature = torch.empty(BATCH_SIZE, n_dimentions, requires_grad=True, device=device)\n",
    "cost1 = tnn.MSELoss()\n",
    "cost2 = tnn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.SGD(vgg_conv.parameters(), lr=LEARNING_RATE)\n",
    "optimizer2 = torch.optim.SGD(vgg_fc.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1200 [00:09<11:33,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/100  batch:19/1200  loss1:5.632685  loss2:2.712877  acc:0.0000 all_acc:0.0000\n",
      "epoch:0/100  batch:20/1200  loss1:7.875229  loss2:2.293536  acc:0.1400 all_acc:0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 22/1200 [00:25<55:39,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/100  batch:21/1200  loss1:5.010005  loss2:2.410365  acc:0.1400 all_acc:0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 23/1200 [00:33<1:23:28,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/100  batch:22/1200  loss1:2.167588  loss2:2.335507  acc:0.1400 all_acc:0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 24/1200 [00:42<1:48:50,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/100  batch:23/1200  loss1:7.920605  loss2:2.284410  acc:0.0800 all_acc:0.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 25/1200 [00:49<2:01:31,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/100  batch:24/1200  loss1:2.753434  loss2:2.226345  acc:0.0600 all_acc:0.0224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 26/1200 [00:57<2:09:27,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/100  batch:25/1200  loss1:5.884584  loss2:2.300778  acc:0.1200 all_acc:0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 27/1200 [01:04<2:12:20,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/100  batch:26/1200  loss1:4.312380  loss2:2.419478  acc:0.0800 all_acc:0.0281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 28/1200 [01:11<2:11:27,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/100  batch:27/1200  loss1:7.332511  loss2:2.321125  acc:0.0400 all_acc:0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 29/1200 [01:19<2:19:14,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/100  batch:28/1200  loss1:13.570882  loss2:2.440329  acc:0.1400 all_acc:0.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 30/1200 [01:25<2:13:17,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/100  batch:29/1200  loss1:4.275620  loss2:2.336364  acc:0.1000 all_acc:0.0347\n"
     ]
    }
   ],
   "source": [
    "file_name = 'train_new_isomap_pureconv_stableisomap_downdimension_{}_isomap_number_{}_neighbors_{}_batch_{}'.format(\n",
    "        n_dimentions, isomap_number, n_neighbors, BATCH_SIZE)\n",
    "if write_log:\n",
    "        writer = SummaryWriter('./runs/{}'.format(file_name))\n",
    "        if not os.path.exists('./model_saved/{}'.format(file_name)):\n",
    "            os.makedirs('./model_saved/{}'.format(file_name))\n",
    "else:\n",
    "        writer = None\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(EPOCH):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
