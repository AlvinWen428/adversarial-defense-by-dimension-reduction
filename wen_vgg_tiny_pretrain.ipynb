{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import deque\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from locally_linear import LocallyLinearBackward\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from model.vgg_tiny import Conv, Fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "memory_gpu=[int(x.split()[2]) for x in open('tmp','r').readlines()]\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=str(np.argmax(memory_gpu))\n",
    "os.system('rm tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCH = 1\n",
    "n_dimentions = 32\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isomap(feature_queue, n_components):\n",
    "    length = len(feature_queue)\n",
    "    for i in range(length):\n",
    "        if i == 0:\n",
    "            feature_tmp = feature_queue.popleft()\n",
    "            features = feature_tmp\n",
    "            feature_to_use = feature_tmp\n",
    "        else:\n",
    "            feature_tmp = feature_queue.popleft()\n",
    "            features = np.concatenate((features, feature_tmp), axis=0)\n",
    "        \n",
    "    feature_input = features\n",
    "    embedding = Isomap(n_components=n_components)\n",
    "    transformed = embedding.fit_transform(feature_input)\n",
    "\n",
    "    return transformed, feature_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isomap_back(X_Que,Y_use,Y_all,Error):\n",
    "#Error has dim:p*N, where p is the dims of every object after isomap N is the batchsize\n",
    "#Y is the feature during the forward process\n",
    "#X is the feature before Isomap\n",
    "\n",
    "    k=4\n",
    "    E=Error.cpu().numpy()\n",
    "    Y_use = Y_use.detach().cpu().numpy()\n",
    "    length=len(X_Que)\n",
    "    for i in range(length):\n",
    "        if i == 0:\n",
    "            feature_tmp = X_Que.popleft()\n",
    "            X_use=feature_tmp\n",
    "            X = feature_tmp\n",
    "        else:\n",
    "            feature_tmp = X_Que.popleft()\n",
    "            X = np.concatenate((X, feature_tmp), axis=0)\n",
    "\n",
    "    Yb=Y_use+E\n",
    "#Calculate all the distances between Yb and all Y\n",
    "    n=Yb.shape\n",
    "    total=Y_all.shape\n",
    "    for i in range(n[0]):\n",
    "        dis=np.zeros(total[0])\n",
    "        Yi=Yb[i]\n",
    "        for j in range(total[0]):\n",
    "            z=(Yi-Y_all[j]).reshape(-1,1)\n",
    "            dis[j]=np.matmul(z.transpose(),z)\n",
    "        idx = np.argpartition(dis, k)[0:k]\n",
    "        for m in range(k):\n",
    "            if m==0:\n",
    "                Y_near=Y_all[idx[m]].reshape([1,-1])\n",
    "                X_near = X[idx[m]].reshape([1,-1])\n",
    "                Y_bar=Yi.reshape([1,-1])\n",
    "            else:\n",
    "                Y_near=np.concatenate((Y_near,Y_all[idx[m]].reshape([1,-1])),axis=0)\n",
    "                X_near=np.concatenate((X_near,X[idx[m]].reshape([1,-1])),axis=0)\n",
    "                Y_bar=np.concatenate((Y_bar,Yi.reshape([1,-1])),axis=0)\n",
    "        \n",
    "        tmp=np.mat(Y_bar-Y_near)\n",
    "        Z=tmp*tmp.transpose()\n",
    "        One=np.mat(np.ones([k, 1]))\n",
    "        X_near=np.mat(X_near)\n",
    "        w=(np.linalg.pinv(Z))*One/(One.transpose()*(np.linalg.pinv(Z))*One)\n",
    "        if i==0:\n",
    "            X_back=(X_near.transpose()*w).reshape([1,-1])\n",
    "        else:\n",
    "            X_back=np.concatenate((X_back,(X_near*w).reshape([1,-1])),axis=0)\n",
    "\n",
    "        return X_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(28),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "data_train = dsets.MNIST(root = \"./data/\",\n",
    "                         transform=transform,\n",
    "                            train = True,\n",
    "                            download = True)\n",
    "\n",
    "data_test = dsets.MNIST(root=\"./data/\",\n",
    "                        transform=transform,\n",
    "                           train = False)\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(dataset=data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(dataset=data_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_conv = Conv().to(device)\n",
    "vgg_fc = Fc(input_channel=32, output_channel=10).to(device)\n",
    "\n",
    "vgg_conv.load_state_dict(torch.load('./model_saved/conv_train_isomap_pureconv_SGD_downdimension_50_isomap_number_5000_neighbors_7_epoch_19.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isomap_feature = torch.empty(BATCH_SIZE, n_dimentions, requires_grad=True, device=device)\n",
    "cost1 = tnn.MSELoss()\n",
    "cost2 = tnn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.SGD(vgg_conv.parameters(), lr=LEARNING_RATE)\n",
    "optimizer2 = torch.optim.SGD(vgg_fc.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 10]) torch.Size([50])\n",
      "torch.Size([1, 1568])\n",
      "epoch:0/1  batch:19/1200  loss1:115.921761  loss2:2.333678  acc:0.0800\n",
      "torch.Size([50, 10]) torch.Size([50])\n",
      "torch.Size([1, 1568])\n",
      "epoch:0/1  batch:20/1200  loss1:138.633530  loss2:2.359176  acc:0.0800\n",
      "torch.Size([50, 10]) torch.Size([50])\n",
      "torch.Size([1, 1568])\n",
      "epoch:0/1  batch:21/1200  loss1:152.151215  loss2:2.351386  acc:0.0200\n",
      "torch.Size([50, 10]) torch.Size([50])\n",
      "torch.Size([1, 1568])\n",
      "epoch:0/1  batch:22/1200  loss1:137.919205  loss2:2.310191  acc:0.1800\n",
      "torch.Size([50, 10]) torch.Size([50])\n",
      "torch.Size([1, 1568])\n",
      "epoch:0/1  batch:23/1200  loss1:168.398315  loss2:2.296554  acc:0.2000\n",
      "torch.Size([50, 10]) torch.Size([50])\n",
      "torch.Size([1, 1568])\n",
      "epoch:0/1  batch:24/1200  loss1:152.590515  loss2:2.301977  acc:0.0800\n",
      "torch.Size([50, 10]) torch.Size([50])\n",
      "torch.Size([1, 1568])\n",
      "epoch:0/1  batch:25/1200  loss1:133.613953  loss2:2.312100  acc:0.0800\n",
      "torch.Size([50, 10]) torch.Size([50])\n",
      "torch.Size([1, 1568])\n",
      "epoch:0/1  batch:26/1200  loss1:110.977318  loss2:2.369189  acc:0.0800\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(EPOCH):\n",
    "#  for i, (images, labels) in enumerate(trainLoader):\n",
    "  vgg_conv.train()\n",
    "  vgg_fc.train()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  train_img_queue = deque(maxlen=1000//BATCH_SIZE)    #构建输入图像的队列\n",
    "  train_label_queue = deque(maxlen=1000//BATCH_SIZE) #构建label的队列\n",
    "  train_vec_queue = deque(maxlen=1000//BATCH_SIZE)    #构建卷积网络输出向量的队列\n",
    "  for batch_idx, (images, labels) in enumerate(trainLoader):\n",
    "    train_img_queue.append(images)   #入队是append，出队是popleft\n",
    "    train_label_queue.append(labels)\n",
    "    \n",
    "    # Forward + Backward + Optimize\n",
    "    \n",
    "#     optimizer1.zero_grad()\n",
    "#     optimizer2.zero_grad()\n",
    "\n",
    "    outputs1 = vgg_conv(images.to(device)) #卷积网络的输出，将图片embedding成512维向量，the shape of output is (batch_size, 512)\n",
    "    #print(images, outputs1)\n",
    "    train_vec_queue.append(outputs1.detach().cpu().numpy())\n",
    "#     print(train_vec_queue.qsize())\n",
    "#     print(train_vec_queue.get_nowait().shape)\n",
    "    \n",
    "    if len(train_img_queue) == 1000//BATCH_SIZE:  #等队列满了之后，开始让所有图片进入isomap，然后pop出队首的数据进行反向传播\n",
    "        isomap_forward, feature_to_use = isomap(copy.deepcopy(train_vec_queue), n_components=32)#将1000张图片通过卷积层得到的embedding向量输入isomap层，获得降维后的结果\n",
    "        #isomap: numpy.ndarray   feature_to_use: numpy.ndarray\n",
    "        feature_to_use = torch.Tensor(feature_to_use)\n",
    "        if outputs1.is_cuda:\n",
    "            batch_feature = torch.from_numpy(isomap_forward[:BATCH_SIZE]).cuda()\n",
    "        else:\n",
    "            batch_feature = torch.from_numpy(isomap_forward[:BATCH_SIZE])\n",
    "        \n",
    "        batch_feature = batch_feature.float()\n",
    "        \n",
    "#         img_tmp = train_img_queue.popleft()\n",
    "#         label_tmp = train_label_queue.popleft()\n",
    "#         vec_tmp = train_vec_queue.popleft()\n",
    "        \n",
    "        isomap_feature = batch_feature\n",
    "        isomap_feature.requires_grad = True\n",
    "        outputs2 = vgg_fc(isomap_feature)\n",
    "        batch_label = train_label_queue.popleft()\n",
    "        print(outputs2.shape, batch_label.shape)\n",
    "        loss2 = cost2(outputs2, batch_label.squeeze().to(device))\n",
    "        \n",
    "        #---------------------------------------\n",
    "        optimizer2.zero_grad()\n",
    "        loss2.backward()\n",
    "        optimizer2.step()\n",
    "        \n",
    "        grad = isomap_feature.grad\n",
    "        \n",
    "        E = grad*LEARNING_RATE\n",
    "        \n",
    "        x_hat = isomap_back(copy.deepcopy(train_vec_queue), isomap_feature, isomap_forward, E)\n",
    "        #all X:copy.deepcopy(train_vec_queue) Y:isomap_feature    all Y: isomap_forward     y error:E\n",
    "        x_hat = torch.Tensor(x_hat)\n",
    "        print(x_hat.shape)\n",
    "        loss1 = cost1(feature_to_use.to(device), x_hat.to(device))\n",
    "        loss1.requires_grad = True\n",
    "        optimizer1.zero_grad()\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "        \n",
    "        train_vec_queue.popleft()\n",
    "        train_img_queue.popleft()\n",
    "        \n",
    "        pred = torch.max(outputs2.data, 1)[1]\n",
    "        train_correct = (pred == batch_label.to(device)).sum()\n",
    "        \n",
    "        print('epoch:{}/{}  batch:{}/{}  loss1:{:.6f}  loss2:{:.6f}  acc:{:.4f}'.format(epoch, EPOCH, batch_idx,\n",
    "                                                                         data_train.__len__() // BATCH_SIZE, loss1,\n",
    "                                                                         loss2, float(train_correct) / BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
