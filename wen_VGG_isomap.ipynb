{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import deque\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from locally_linear import LocallyLinearBackward\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from model.vgg_tiny import Conv, Fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "memory_gpu=[int(x.split()[2]) for x in open('tmp','r').readlines()]\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=str(np.argmax(memory_gpu))\n",
    "os.system('rm tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCH = 1\n",
    "n_dimentions = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(28),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "data_train = dsets.MNIST(root = \"./data/\",\n",
    "                         transform=transform,\n",
    "                            train = True,\n",
    "                            download = True)\n",
    "\n",
    "data_test = dsets.MNIST(root=\"./data/\",\n",
    "                        transform=transform,\n",
    "                           train = False)\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(dataset=data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(dataset=data_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGG_conv(tnn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_conv, self).__init__()\n",
    "        self.layer1 = tnn.Sequential(\n",
    "\n",
    "            # 1-1 conv layer\n",
    "            tnn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(64),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 1-2 conv layer\n",
    "            tnn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(64),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 1 Pooling layer\n",
    "            tnn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer2 = tnn.Sequential(\n",
    "\n",
    "            # 2-1 conv layer\n",
    "            tnn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(128),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 2-2 conv layer\n",
    "            tnn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(128),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 2 Pooling lyaer\n",
    "            tnn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer3 = tnn.Sequential(\n",
    "\n",
    "            # 3-1 conv layer\n",
    "            tnn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(256),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 3-2 conv layer\n",
    "            tnn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(256),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 3 Pooling layer\n",
    "            tnn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer4 = tnn.Sequential(\n",
    "\n",
    "            # 4-1 conv layer\n",
    "            tnn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(512),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 4-2 conv layer\n",
    "            tnn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(512),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 4 Pooling layer\n",
    "            tnn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # self.layer5 = tnn.Sequential(\n",
    "        #\n",
    "        #     # 5-1 conv layer\n",
    "        #     tnn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        #     tnn.BatchNorm2d(512),\n",
    "        #     tnn.ReLU(),\n",
    "        #\n",
    "        #     # 5-2 conv layer\n",
    "        #     tnn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        #     tnn.BatchNorm2d(512),\n",
    "        #     tnn.ReLU(),\n",
    "        #\n",
    "        #     # 5 Pooling layer\n",
    "        #    tnn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer6 = tnn.Sequential(\n",
    "\n",
    "            # 6 Fully connected layer\n",
    "            # Dropout layer omitted since batch normalization is used.\n",
    "            tnn.Linear(512, 512),\n",
    "            tnn.BatchNorm1d(512),\n",
    "            tnn.ReLU())\n",
    "\n",
    "\n",
    "        self.layer7 = tnn.Sequential(\n",
    "\n",
    "            # 7 Fully connected layer\n",
    "            # Dropout layer omitted since batch normalization is used.\n",
    "            tnn.Linear(512, 512,\n",
    "            tnn.BatchNorm1d(512)),\n",
    "            tnn.ReLU())\n",
    "    \n",
    "    def forward(self, x):\n",
    "      out = self.layer1(x)\n",
    "      out = self.layer2(out)\n",
    "      out = self.layer3(out)\n",
    "      out = self.layer4(out)\n",
    "   #   out = self.layer5(out)\n",
    "      vgg16_features = out.view(out.size(0), -1)\n",
    "      out = self.layer6(vgg16_features)\n",
    "      out = self.layer7(out)\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGG_fc(tnn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_fc, self).__init__()\n",
    "        self.layer8 = tnn.Sequential(\n",
    "\n",
    "        # 8 output layer\n",
    "        tnn.Linear(32, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer8(x)\n",
    "#         out = F.softmax(out, dim=1)  #CrossEntropy 不能用这个\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isomap(feature_queue, n_components):\n",
    "    length = len(feature_queue)\n",
    "    for i in range(length):\n",
    "        if i == 0:\n",
    "            feature_tmp = feature_queue.popleft()\n",
    "            features = feature_tmp\n",
    "            feature_to_use = feature_tmp\n",
    "        else:\n",
    "            feature_tmp = feature_queue.popleft()\n",
    "            features = np.concatenate((features, feature_tmp), axis=0)\n",
    "        \n",
    "    feature_input = features\n",
    "    embedding = Isomap(n_components=n_components)\n",
    "    transformed = embedding.fit_transform(feature_input)\n",
    "\n",
    "    return transformed, feature_to_use\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isomap_back(X_Que,Y_use,Y_all,Error):\n",
    "#Error has dim:p*N, where p is the dims of every object after isomap N is the batchsize\n",
    "#Y is the feature during the forward process\n",
    "#X is the feature before Isomap\n",
    "\n",
    "    k=4\n",
    "    E=Error.cpu().numpy()\n",
    "    Y_use = Y_use.detach().cpu().numpy()\n",
    "    length=len(X_Que)\n",
    "    for i in range(length):\n",
    "        if i == 0:\n",
    "            feature_tmp = X_Que.popleft()\n",
    "            X_use=feature_tmp\n",
    "            X = feature_tmp\n",
    "        else:\n",
    "            feature_tmp = X_Que.popleft()\n",
    "            X = np.concatenate((X, feature_tmp), axis=0)\n",
    "\n",
    "    Yb=Y_use+E\n",
    "#Calculate all the distances between Yb and all Y\n",
    "    n=Yb.shape\n",
    "    total=Y_all.shape\n",
    "    for i in range(n[0]):\n",
    "        dis=np.zeros(total[0])\n",
    "        Yi=Yb[i]\n",
    "        for j in range(total[0]):\n",
    "            z=(Yi-Y_all[j]).reshape(-1,1)\n",
    "            dis[j]=np.matmul(z.transpose(),z)\n",
    "        idx = np.argpartition(dis, k)[0:k]\n",
    "        for m in range(k):\n",
    "            if m==0:\n",
    "                Y_near=Y_all[idx[m]].reshape([1,-1])\n",
    "                X_near = X[idx[m]].reshape([1,-1])\n",
    "                Y_bar=Yi.reshape([1,-1])\n",
    "            else:\n",
    "                Y_near=np.concatenate((Y_near,Y_all[idx[m]].reshape([1,-1])),axis=0)\n",
    "                X_near=np.concatenate((X_near,X[idx[m]].reshape([1,-1])),axis=0)\n",
    "                Y_bar=np.concatenate((Y_bar,Yi.reshape([1,-1])),axis=0)\n",
    "        \n",
    "        tmp=np.mat(Y_bar-Y_near)\n",
    "        Z=tmp*tmp.transpose()\n",
    "        One=np.mat(np.ones([k, 1]))\n",
    "        X_near=np.mat(X_near)\n",
    "        w=(np.linalg.pinv(Z))*One/(One.transpose()*(np.linalg.pinv(Z))*One)\n",
    "        if i==0:\n",
    "            X_back=(X_near.transpose()*w).reshape([1,-1])\n",
    "        else:\n",
    "            X_back=np.concatenate((X_back,(X_near*w).reshape([1,-1])),axis=0)\n",
    "\n",
    "        return X_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg_conv = VGG_conv().to(device)\n",
    "# vgg_conv.cuda()\n",
    "vgg_fc = VGG_fc().to(device)\n",
    "# vgg_fc.cuda()\n",
    "\n",
    "isomap_feature = torch.empty(BATCH_SIZE, n_dimentions, requires_grad=True, device=device)\n",
    "cost1 = tnn.MSELoss()\n",
    "cost2 = tnn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.SGD(vgg_conv.parameters(), lr=LEARNING_RATE)\n",
    "optimizer2 = torch.optim.SGD(vgg_fc.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/1  batch:19/1200  loss1:0.029237  loss2:2.488489  acc:0.0800\n",
      "epoch:0/1  batch:20/1200  loss1:0.020116  loss2:2.625279  acc:0.0800\n",
      "epoch:0/1  batch:21/1200  loss1:0.026848  loss2:2.292303  acc:0.2000\n",
      "epoch:0/1  batch:22/1200  loss1:0.027397  loss2:2.370904  acc:0.1600\n",
      "epoch:0/1  batch:23/1200  loss1:0.021815  loss2:2.884284  acc:0.0800\n",
      "epoch:0/1  batch:24/1200  loss1:0.022291  loss2:2.578059  acc:0.0600\n",
      "epoch:0/1  batch:25/1200  loss1:0.031076  loss2:2.644250  acc:0.0800\n",
      "epoch:0/1  batch:26/1200  loss1:0.030357  loss2:2.553852  acc:0.0600\n",
      "epoch:0/1  batch:27/1200  loss1:0.022617  loss2:2.697981  acc:0.0400\n",
      "epoch:0/1  batch:28/1200  loss1:0.026064  loss2:2.626992  acc:0.0800\n",
      "epoch:0/1  batch:29/1200  loss1:0.028195  loss2:2.755454  acc:0.0600\n",
      "epoch:0/1  batch:30/1200  loss1:0.022766  loss2:2.612507  acc:0.1400\n",
      "epoch:0/1  batch:31/1200  loss1:0.030420  loss2:2.526416  acc:0.1000\n",
      "epoch:0/1  batch:32/1200  loss1:0.029058  loss2:2.607552  acc:0.1000\n",
      "epoch:0/1  batch:33/1200  loss1:0.031753  loss2:2.648163  acc:0.1000\n",
      "epoch:0/1  batch:153/1200  loss1:0.024934  loss2:2.582770  acc:0.0400\n",
      "epoch:0/1  batch:154/1200  loss1:0.022646  loss2:2.560573  acc:0.2000\n",
      "epoch:0/1  batch:155/1200  loss1:0.026547  loss2:2.603406  acc:0.0800\n",
      "epoch:0/1  batch:156/1200  loss1:0.022568  loss2:2.434067  acc:0.1000\n",
      "epoch:0/1  batch:157/1200  loss1:0.027134  loss2:2.335829  acc:0.1600\n",
      "epoch:0/1  batch:158/1200  loss1:0.045371  loss2:2.507234  acc:0.0800\n",
      "epoch:0/1  batch:159/1200  loss1:0.022463  loss2:2.518856  acc:0.1000\n",
      "epoch:0/1  batch:160/1200  loss1:0.021816  loss2:2.504429  acc:0.1000\n",
      "epoch:0/1  batch:161/1200  loss1:0.024997  loss2:2.573676  acc:0.1200\n",
      "epoch:0/1  batch:162/1200  loss1:0.026887  loss2:2.484475  acc:0.1000\n",
      "epoch:0/1  batch:163/1200  loss1:0.021815  loss2:2.461322  acc:0.1400\n",
      "epoch:0/1  batch:164/1200  loss1:0.022509  loss2:2.390879  acc:0.1000\n",
      "epoch:0/1  batch:165/1200  loss1:0.035793  loss2:2.537217  acc:0.0600\n",
      "epoch:0/1  batch:166/1200  loss1:0.022545  loss2:2.418282  acc:0.0600\n",
      "epoch:0/1  batch:167/1200  loss1:0.019967  loss2:2.503999  acc:0.0800\n",
      "epoch:0/1  batch:168/1200  loss1:0.037237  loss2:2.527460  acc:0.1000\n",
      "epoch:0/1  batch:169/1200  loss1:0.026572  loss2:2.409677  acc:0.0800\n",
      "epoch:0/1  batch:170/1200  loss1:0.022499  loss2:2.510462  acc:0.0600\n",
      "epoch:0/1  batch:171/1200  loss1:0.025194  loss2:2.487094  acc:0.0600\n",
      "epoch:0/1  batch:172/1200  loss1:0.025706  loss2:2.227925  acc:0.2200\n",
      "epoch:0/1  batch:173/1200  loss1:0.033599  loss2:2.390129  acc:0.0600\n",
      "epoch:0/1  batch:174/1200  loss1:0.023424  loss2:2.364980  acc:0.1400\n",
      "epoch:0/1  batch:175/1200  loss1:0.022147  loss2:2.558498  acc:0.0200\n",
      "epoch:0/1  batch:176/1200  loss1:0.029310  loss2:2.446810  acc:0.0800\n",
      "epoch:0/1  batch:177/1200  loss1:0.029224  loss2:2.380399  acc:0.0400\n",
      "epoch:0/1  batch:178/1200  loss1:0.031900  loss2:2.344573  acc:0.1000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(EPOCH):\n",
    "#  for i, (images, labels) in enumerate(trainLoader):\n",
    "  vgg_conv.train()\n",
    "  vgg_fc.train()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  train_img_queue = deque(maxlen=1000//BATCH_SIZE)    #构建输入图像的队列\n",
    "  train_label_queue = deque(maxlen=1000//BATCH_SIZE) #构建label的队列\n",
    "  train_vec_queue = deque(maxlen=1000//BATCH_SIZE)    #构建卷积网络输出向量的队列\n",
    "  for batch_idx, (images, labels) in enumerate(trainLoader):\n",
    "    train_img_queue.append(images)   #入队是append，出队是popleft\n",
    "    train_label_queue.append(labels)\n",
    "    \n",
    "    # Forward + Backward + Optimize\n",
    "    \n",
    "#     optimizer1.zero_grad()\n",
    "#     optimizer2.zero_grad()\n",
    "\n",
    "    outputs1 = vgg_conv(images.to(device)) #卷积网络的输出，将图片embedding成512维向量，the shape of output is (batch_size, 512)\n",
    "    #print(images, outputs1)\n",
    "    train_vec_queue.append(outputs1.detach().cpu().numpy())\n",
    "#     print(train_vec_queue.qsize())\n",
    "#     print(train_vec_queue.get_nowait().shape)\n",
    "    \n",
    "    if len(train_img_queue) == 1000//BATCH_SIZE:  #等队列满了之后，开始让所有图片进入isomap，然后pop出队首的数据进行反向传播\n",
    "        isomap_forward, feature_to_use = isomap(copy.deepcopy(train_vec_queue), n_components=32)#将1000张图片通过卷积层得到的embedding向量输入isomap层，获得降维后的结果\n",
    "        #isomap: numpy.ndarray   feature_to_use: numpy.ndarray\n",
    "        \n",
    "        if outputs1.is_cuda:\n",
    "            batch_feature = torch.from_numpy(isomap_forward[:BATCH_SIZE]).cuda()\n",
    "        else:\n",
    "            batch_feature = torch.from_numpy(isomap_forward[:BATCH_SIZE])\n",
    "        \n",
    "        batch_feature = batch_feature.float()\n",
    "        \n",
    "#         img_tmp = train_img_queue.popleft()\n",
    "#         label_tmp = train_label_queue.popleft()\n",
    "#         vec_tmp = train_vec_queue.popleft()\n",
    "        \n",
    "        isomap_feature = batch_feature\n",
    "        isomap_feature.requires_grad = True\n",
    "        outputs2 = vgg_fc(isomap_feature)\n",
    "        \n",
    "        batch_label = train_label_queue.popleft()\n",
    "        loss2 = cost2(outputs2, batch_label.to(device))\n",
    "        \n",
    "        #---------------------------------------\n",
    "        optimizer2.zero_grad()\n",
    "        loss2.backward()\n",
    "        optimizer2.step()\n",
    "        \n",
    "        grad = isomap_feature.grad\n",
    "        \n",
    "        E = grad*LEARNING_RATE\n",
    "        \n",
    "        x_hat = isomap_back(copy.deepcopy(train_vec_queue), isomap_feature, isomap_forward, E)\n",
    "        #all X:isomap_back(copy.deepcopy(train_vec_queue) Y:isomap_feature    all Y: isomap_forward     y error:E\n",
    "        \n",
    "        feature_to_use = torch.Tensor(feature_to_use)\n",
    "        x_hat = torch.Tensor(x_hat)\n",
    "        loss1 = cost1(feature_to_use.to(device), x_hat.to(device))\n",
    "        loss1.requires_grad = True\n",
    "        optimizer1.zero_grad()\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "        \n",
    "        train_vec_queue.popleft()\n",
    "        train_img_queue.popleft()\n",
    "        \n",
    "        pred = torch.max(outputs2.data, 1)[1]\n",
    "        train_correct = (pred == batch_label.to(device)).sum()\n",
    "        \n",
    "        print('epoch:{}/{}  batch:{}/{}  loss1:{:.6f}  loss2:{:.6f}  acc:{:.4f}'.format(epoch, EPOCH, batch_idx,\n",
    "                                                                         data_train.__len__() // BATCH_SIZE, loss1,\n",
    "                                                                         loss2, float(train_correct) / BATCH_SIZE))\n",
    "\n",
    "#   vgg_conv.train()\n",
    "#   vgg_fc.train()\n",
    "#   correct = 0\n",
    "#   with torch.no_grad():\n",
    "#     for batch_idx, (val_x, val_y) in enumerate(validation_loader):\n",
    "#         val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "#         output1 = vgg_conv(val_x)\n",
    "        \n",
    "#         output2 = vgg_fc()\n",
    "#         pred = torch.max(output.data, 1)[1]\n",
    "#         correct += (pred == val_y.squeeze(1)).sum()\n",
    "#     acc = float(correct) / validation_set.__len__()\n",
    "#     print('epoch:{}/{} acc:{:.4f} max_val_acc:{}'.format(epoch, EPOCH, acc, max_acc))\n",
    "  \n",
    "        \n",
    "#         Y = isomap_feature.detach().cpu().numpy()\n",
    "        \n",
    "        \n",
    "#         Y_hat = isomap_feature.detach().cpu().numpy()\n",
    "        \n",
    "#         if (np.any(np.isnan(Y))):\n",
    "#             print(\"Nan element\")\n",
    "#         if(np.all(np.isfinite(Y))):\n",
    "#             print(\"\")\n",
    "#         back = LocallyLinearBackward(n_neighbors=10) # n_neighbors is a hyperparameter\n",
    "#         back.fit(Y, Y_hat)\n",
    "        \n",
    "#         X_hat = back.error_backward(feature_to_use.detach().cpu().numpy())\n",
    "#         print(X_hat)\n",
    "#         target = torch.from_numpy(X_hat).to(device)\n",
    "#         loss1 = cost1(feature_to_use, target)\n",
    "        \n",
    "#         optimizer1.zero_grad()\n",
    "#         loss1.backward()\n",
    "#         optimizer1.step()\n",
    "#         #----------------------------------------\n",
    "# #         current_img = train_img_queue.get()\n",
    "# #         current_label = train_label_queue.get()\n",
    "# #         current_vec = train_vec_queue.get()\n",
    "        \n",
    "    \n",
    "    \n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "#     loss = cost(outputs, labels.cuda())\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "    \n",
    "\n",
    "#   print ('Epoch [%d/%d], Loss. %.4f' %(epoch+1, EPOCH, loss.data[0]))\n",
    "#   print('Test Accuracy of the model on the training set: %d %%' % (100 * correct / total))\n",
    "\n",
    "# # Test the model\n",
    "#   vgg16.eval()\n",
    "#   correct = 0\n",
    "#   total = 0\n",
    "\n",
    "#   for images, labels in testLoader:\n",
    "#     images = Variable(images).cuda()\n",
    "#     outputs = vgg16(images)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     total += labels.size(0)\n",
    "#     correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "#   print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "# # Save the Trained Model\n",
    "# torch.save(vgg16.state_dict(),'checkpoint_without_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
