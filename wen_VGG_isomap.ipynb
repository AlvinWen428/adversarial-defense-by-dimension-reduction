{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import deque\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from locally_linear import LocallyLinearBackward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "memory_gpu=[int(x.split()[2]) for x in open('tmp','r').readlines()]\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=str(np.argmax(memory_gpu))\n",
    "os.system('rm tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCH = 1\n",
    "n_dimentions = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(28),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "data_train = dsets.MNIST(root = \"./data/\",\n",
    "                         transform=transform,\n",
    "                            train = True,\n",
    "                            download = True)\n",
    "\n",
    "data_test = dsets.MNIST(root=\"./data/\",\n",
    "                        transform=transform,\n",
    "                           train = False)\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(dataset=data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(dataset=data_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGG_conv(tnn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_conv, self).__init__()\n",
    "        self.layer1 = tnn.Sequential(\n",
    "\n",
    "            # 1-1 conv layer\n",
    "            tnn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(64),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 1-2 conv layer\n",
    "            tnn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(64),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 1 Pooling layer\n",
    "            tnn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer2 = tnn.Sequential(\n",
    "\n",
    "            # 2-1 conv layer\n",
    "            tnn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(128),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 2-2 conv layer\n",
    "            tnn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(128),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 2 Pooling lyaer\n",
    "            tnn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer3 = tnn.Sequential(\n",
    "\n",
    "            # 3-1 conv layer\n",
    "            tnn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(256),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 3-2 conv layer\n",
    "            tnn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(256),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 3 Pooling layer\n",
    "            tnn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer4 = tnn.Sequential(\n",
    "\n",
    "            # 4-1 conv layer\n",
    "            tnn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(512),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 4-2 conv layer\n",
    "            tnn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(512),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 4 Pooling layer\n",
    "            tnn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # self.layer5 = tnn.Sequential(\n",
    "        #\n",
    "        #     # 5-1 conv layer\n",
    "        #     tnn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        #     tnn.BatchNorm2d(512),\n",
    "        #     tnn.ReLU(),\n",
    "        #\n",
    "        #     # 5-2 conv layer\n",
    "        #     tnn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        #     tnn.BatchNorm2d(512),\n",
    "        #     tnn.ReLU(),\n",
    "        #\n",
    "        #     # 5 Pooling layer\n",
    "        #    tnn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer6 = tnn.Sequential(\n",
    "\n",
    "            # 6 Fully connected layer\n",
    "            # Dropout layer omitted since batch normalization is used.\n",
    "            tnn.Linear(512, 512),\n",
    "            tnn.BatchNorm1d(512),\n",
    "            tnn.ReLU())\n",
    "\n",
    "\n",
    "        self.layer7 = tnn.Sequential(\n",
    "\n",
    "            # 7 Fully connected layer\n",
    "            # Dropout layer omitted since batch normalization is used.\n",
    "            tnn.Linear(512, 512,\n",
    "            tnn.BatchNorm1d(512)),\n",
    "            tnn.ReLU())\n",
    "    \n",
    "    def forward(self, x):\n",
    "      out = self.layer1(x)\n",
    "      out = self.layer2(out)\n",
    "      out = self.layer3(out)\n",
    "      out = self.layer4(out)\n",
    "   #   out = self.layer5(out)\n",
    "      vgg16_features = out.view(out.size(0), -1)\n",
    "      out = self.layer6(vgg16_features)\n",
    "      out = self.layer7(out)\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGG_fc(tnn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_fc, self).__init__()\n",
    "        self.layer8 = tnn.Sequential(\n",
    "\n",
    "        # 8 output layer\n",
    "        tnn.Linear(32, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer8(x)\n",
    "#         out = F.softmax(out, dim=1)  #CrossEntropy 不能用这个\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isomap(feature_queue, n_components):\n",
    "    length = len(feature_queue)\n",
    "    for i in range(length):\n",
    "        if i == 0:\n",
    "            feature_tmp = feature_queue.popleft()\n",
    "            features = feature_tmp\n",
    "            feature_to_use = feature_tmp\n",
    "        else:\n",
    "            feature_tmp = feature_queue.popleft()\n",
    "            features = np.concatenate((features, feature_tmp), axis=0)\n",
    "        \n",
    "    feature_input = features\n",
    "    embedding = Isomap(n_components=n_components)\n",
    "    transformed = embedding.fit_transform(feature_input)\n",
    "\n",
    "    return transformed, feature_to_use\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-31-1481f5cd4b7a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-1481f5cd4b7a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def isomap_back(feature_queue, isomap_forward, E):\u001b[0m\n\u001b[0m                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def isomap_back(feature_queue, isomap_forward, E):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_conv = VGG_conv().to(device)\n",
    "# vgg_conv.cuda()\n",
    "vgg_fc = VGG_fc().to(device)\n",
    "# vgg_fc.cuda()\n",
    "\n",
    "isomap_feature = torch.empty(BATCH_SIZE, n_dimentions, requires_grad=True, device=device)\n",
    "cost1 = tnn.MSELoss()\n",
    "cost2 = tnn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.SGD(vgg_conv.parameters(), lr=LEARNING_RATE)\n",
    "optimizer2 = torch.optim.SGD([{'params':vgg_fc.parameters()}\n",
    "                               ,{'params':isomap_feature}\n",
    "                              ], lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[-0.0018, -0.0002, -0.0038,  ...,  0.0025,  0.0015,  0.0038],\n",
      "        [-0.0021, -0.0002, -0.0039,  ...,  0.0025,  0.0022,  0.0034],\n",
      "        [-0.0024,  0.0001, -0.0030,  ...,  0.0019,  0.0012,  0.0020],\n",
      "        ...,\n",
      "        [ 0.0017,  0.0017,  0.0005,  ...,  0.0029, -0.0024, -0.0041],\n",
      "        [ 0.0016,  0.0021,  0.0011,  ...,  0.0039, -0.0009, -0.0040],\n",
      "        [ 0.0003,  0.0007,  0.0011,  ..., -0.0017,  0.0031,  0.0009]],\n",
      "       device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'W' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-257128b05d44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocallyLinearBackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# n_neighbors is a hyperparameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mX_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_to_use\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/DATA4_DB3/data/wen/isomap/workspace/locally_linear.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, Y, Y_hat, return_error)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples_to_use\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocally_linear_backward_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mreturn_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/DATA4_DB3/data/wen/isomap/workspace/locally_linear.py\u001b[0m in \u001b[0;36mlocally_linear_backward_parameters\u001b[0;34m(Y, Y_hat, n_neighbors, method, reg, n_jobs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbarycenter_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLocallyLinearBackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'W' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(EPOCH):\n",
    "#  for i, (images, labels) in enumerate(trainLoader):\n",
    "  vgg_conv.train()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  train_img_queue = deque(maxlen=1000//BATCH_SIZE)    #构建输入图像的队列\n",
    "  train_label_queue = deque(maxlen=1000//BATCH_SIZE) #构建label的队列\n",
    "  train_vec_queue = deque(maxlen=1000//BATCH_SIZE)    #构建卷积网络输出向量的队列\n",
    "  for images, labels in trainLoader:\n",
    "    train_img_queue.append(images)   #入队是append，出队是popleft\n",
    "    train_label_queue.append(labels)\n",
    "    \n",
    "    # Forward + Backward + Optimize\n",
    "    \n",
    "#     optimizer1.zero_grad()\n",
    "#     optimizer2.zero_grad()\n",
    "\n",
    "    outputs1 = vgg_conv(images.to(device)) #卷积网络的输出，将图片embedding成512维向量，the shape of output is (batch_size, 512)\n",
    "    \n",
    "    train_vec_queue.append(outputs1.detach().cpu().numpy())\n",
    "    \n",
    "#     print(train_vec_queue.qsize())\n",
    "#     print(train_vec_queue.get_nowait().shape)\n",
    "    \n",
    "    if len(train_img_queue) == 1000//BATCH_SIZE:  #等队列满了之后，开始让所有图片进入isomap，然后pop出队首的数据进行反向传播\n",
    "        isomap_forward, feature_to_use = isomap(copy.deepcopy(train_vec_queue), n_components=32)#将1000张图片通过卷积层得到的embedding向量输入isomap层，获得降维后的结果\n",
    "        #isomap: numpy.ndarray   feature_to_use: numpy.ndarray\n",
    "        \n",
    "        if outputs1.is_cuda:\n",
    "            batch_feature = torch.from_numpy(isomap_forward[:BATCH_SIZE]).cuda()\n",
    "        else:\n",
    "            batch_feature = torch.from_numpy(isomap_forward[:BATCH_SIZE])\n",
    "        \n",
    "        batch_feature = batch_feature.float()\n",
    "        \n",
    "#         img_tmp = train_img_queue.popleft()\n",
    "#         label_tmp = train_label_queue.popleft()\n",
    "#         vec_tmp = train_vec_queue.popleft()\n",
    "        \n",
    "        isomap_feature = batch_feature\n",
    "        isomap_feature.requires_grad = True\n",
    "        outputs = vgg_fc(isomap_feature)\n",
    "        \n",
    "        \n",
    "        loss2 = cost2(outputs, labels.to(device))\n",
    "        \n",
    "        #---------------------------------------\n",
    "        optimizer2.zero_grad()\n",
    "        loss2.backward()\n",
    "        optimizer2.step()\n",
    "        \n",
    "        grad = isomap_feature.grad\n",
    "        \n",
    "        E = grad*LEARNING_RATE\n",
    "        \n",
    "        x_hat = isomap_back(copy.deepcopy(train_vec_queue), isomap_feature, E)\n",
    "        \n",
    "        Y = isomap_feature.detach().cpu().numpy()\n",
    "        \n",
    "   \n",
    "        \n",
    "        Y_hat = isomap_feature.detach().cpu().numpy()\n",
    "        \n",
    "        if (np.any(np.isnan(Y))):\n",
    "            print(\"Nan element\")\n",
    "        if(np.all(np.isfinite(Y))):\n",
    "            print(\"\")\n",
    "        back = LocallyLinearBackward(n_neighbors=10) # n_neighbors is a hyperparameter\n",
    "        back.fit(Y, Y_hat)\n",
    "        \n",
    "        X_hat = back.error_backward(feature_to_use.detach().cpu().numpy())\n",
    "        target = torch.from_numpy(X_hat).to(device)\n",
    "        loss1 = cost1(feature_to_use, target)\n",
    "        \n",
    "        optimizer1.zero_grad()\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "        #----------------------------------------\n",
    "#         current_img = train_img_queue.get()\n",
    "#         current_label = train_label_queue.get()\n",
    "#         current_vec = train_vec_queue.get()\n",
    "        \n",
    "    \n",
    "    \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "#     loss = cost(outputs, labels.cuda())\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "  print ('Epoch [%d/%d], Loss. %.4f' %\n",
    "             (epoch+1, EPOCH, loss.data[0]))\n",
    "  print('Test Accuracy of the model on the training set: %d %%' % (100 * correct / total))\n",
    "\n",
    "# # Test the model\n",
    "#   vgg16.eval()\n",
    "#   correct = 0\n",
    "#   total = 0\n",
    "\n",
    "#   for images, labels in testLoader:\n",
    "#     images = Variable(images).cuda()\n",
    "#     outputs = vgg16(images)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     total += labels.size(0)\n",
    "#     correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "#   print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "# # Save the Trained Model\n",
    "# torch.save(vgg16.state_dict(),'checkpoint_without_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testModel = VGG_fc()\n",
    "# input dimention = 32\n",
    "Input = torch.ones(50,32)\n",
    "Input.requires_grad = True\n",
    "optimizer = torch.optim.Adam([{'params':testModel.parameters()},\n",
    "                           {'params':Input}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = testModel(Input)\n",
    "\n",
    "cost = tnn.CrossEntropyLoss()\n",
    "loss = cost(output, torch.ones(50).long())\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0011, -0.0017,  0.0018,  ...,  0.0016,  0.0015,  0.0004],\n",
       "        [-0.0011, -0.0017,  0.0018,  ...,  0.0016,  0.0015,  0.0004],\n",
       "        [-0.0011, -0.0017,  0.0018,  ...,  0.0016,  0.0015,  0.0004],\n",
       "        ...,\n",
       "        [-0.0011, -0.0017,  0.0018,  ...,  0.0016,  0.0015,  0.0004],\n",
       "        [-0.0011, -0.0017,  0.0018,  ...,  0.0016,  0.0015,  0.0004],\n",
       "        [-0.0011, -0.0017,  0.0018,  ...,  0.0016,  0.0015,  0.0004]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input = Input *0 + torch.ones((50,32))\n",
    "Input.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Input = torch.from_numpy(np.ones((50,32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Y = np.random.randint(0,100,(20,5))\n",
    "idx = np.random.randint(0,20,(20,3))\n",
    "weight = np.random.rand(20,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = np.reshape(weight, weight.shape+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight.shape\n",
    "tmp1 = Y[idx] * weight\n",
    "tmp = np.empty(Y.shape)\n",
    "for i,w in enumerate(weight):\n",
    "    tmp[i] = np.dot(w.T, Y[idx][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(tmp1, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.07793567e-28,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 2.01948392e-28, 0.00000000e+00, 5.04870979e-29,\n",
       "        0.00000000e+00],\n",
       "       [2.01948392e-28, 8.07793567e-28, 0.00000000e+00, 8.07793567e-28,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.04870979e-29,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 2.01948392e-28, 5.04870979e-29, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 2.01948392e-28, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.01948392e-28,\n",
       "        2.01948392e-28],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        8.07793567e-28],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 5.04870979e-29, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.01948392e-28],\n",
       "       [0.00000000e+00, 1.26217745e-29, 2.01948392e-28, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 5.04870979e-29, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 2.01948392e-28, 0.00000000e+00, 2.01948392e-28,\n",
       "        8.07793567e-28],\n",
       "       [0.00000000e+00, 0.00000000e+00, 2.01948392e-28, 2.01948392e-28,\n",
       "        5.04870979e-29],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.sum(tmp1, axis=1)-tmp)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
