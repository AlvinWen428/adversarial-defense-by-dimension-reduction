{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import queue\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from locally_linear import LocallyLinearBackward\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "memory_gpu=[int(x.split()[2]) for x in open('tmp','r').readlines()]\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=str(np.argmax(memory_gpu))\n",
    "os.system('rm tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCH = 1\n",
    "n_dimentions = 32\n",
    "n_neighbors = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(28),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "data_train = dsets.MNIST(root = \"./data/\",\n",
    "                         transform=transform,\n",
    "                            train = True,\n",
    "                            download = True)\n",
    "\n",
    "data_test = dsets.MNIST(root=\"./data/\",\n",
    "                        transform=transform,\n",
    "                           train = False)\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(dataset=data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(dataset=data_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class VGG_conv(tnn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_conv, self).__init__()\n",
    "        self.layer1 = tnn.Sequential(\n",
    "\n",
    "            # 1-1 conv layer\n",
    "            tnn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(64),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 1-2 conv layer\n",
    "            tnn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(64),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 1 Pooling layer\n",
    "            tnn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer2 = tnn.Sequential(\n",
    "\n",
    "            # 2-1 conv layer\n",
    "            tnn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(128),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 2-2 conv layer\n",
    "            tnn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(128),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 2 Pooling lyaer\n",
    "            tnn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer3 = tnn.Sequential(\n",
    "\n",
    "            # 3-1 conv layer\n",
    "            tnn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(256),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 3-2 conv layer\n",
    "            tnn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(256),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 3 Pooling layer\n",
    "            tnn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer4 = tnn.Sequential(\n",
    "\n",
    "            # 4-1 conv layer\n",
    "            tnn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(512),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 4-2 conv layer\n",
    "            tnn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            tnn.BatchNorm2d(512),\n",
    "            tnn.ReLU(),\n",
    "\n",
    "            # 4 Pooling layer\n",
    "            tnn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # self.layer5 = tnn.Sequential(\n",
    "        #\n",
    "        #     # 5-1 conv layer\n",
    "        #     tnn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        #     tnn.BatchNorm2d(512),\n",
    "        #     tnn.ReLU(),\n",
    "        #\n",
    "        #     # 5-2 conv layer\n",
    "        #     tnn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        #     tnn.BatchNorm2d(512),\n",
    "        #     tnn.ReLU(),\n",
    "        #\n",
    "        #     # 5 Pooling layer\n",
    "        #    tnn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer6 = tnn.Sequential(\n",
    "\n",
    "            # 6 Fully connected layer\n",
    "            # Dropout layer omitted since batch normalization is used.\n",
    "            tnn.Linear(512, 512),\n",
    "            tnn.BatchNorm1d(512),\n",
    "            tnn.ReLU())\n",
    "\n",
    "\n",
    "        self.layer7 = tnn.Sequential(\n",
    "\n",
    "            # 7 Fully connected layer\n",
    "            # Dropout layer omitted since batch normalization is used.\n",
    "            tnn.Linear(512, 512,\n",
    "            tnn.BatchNorm1d(512)),\n",
    "            tnn.ReLU())\n",
    "    \n",
    "    def forward(self, x):\n",
    "      out = self.layer1(x)\n",
    "      out = self.layer2(out)\n",
    "      out = self.layer3(out)\n",
    "      out = self.layer4(out)\n",
    "   #   out = self.layer5(out)\n",
    "      vgg16_features = out.view(out.size(0), -1)\n",
    "      out = self.layer6(vgg16_features)\n",
    "      out = self.layer7(out)\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class VGG_fc(tnn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_fc, self).__init__()\n",
    "        self.layer8 = tnn.Sequential(\n",
    "\n",
    "        # 8 output layer\n",
    "        tnn.Linear(32, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer8(x)\n",
    "#         out = F.softmax(out, dim=1)  #CrossEntropy 不能用这个\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def isomap(features, n_components):\n",
    "#     length = feature_queue.qsize()\n",
    "#     for i in range(length):\n",
    "#         if i == 0:\n",
    "#             feature_tmp = feature_queue.get()\n",
    "#             feature_queue.put(feature_tmp)\n",
    "#             features = feature_tmp\n",
    "#         else:\n",
    "#             feature_tmp = feature_queue.get()\n",
    "#             feature_queue.put(feature_tmp)\n",
    "#             features = torch.cat((features, feature_tmp), dim=0)\n",
    "        \n",
    "    feature_input = features\n",
    "    embedding = Isomap(n_components=n_components)\n",
    "    transformed = embedding.fit_transform(feature_input)\n",
    "#     if features.is_cuda:\n",
    "#         output = torch.from_numpy(transformed).cuda()\n",
    "#     else:\n",
    "#         output = torch.from_numpy(transformed)\n",
    "    output = transformed\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_queue_elements(feature_queue):\n",
    "    length = feature_queue.qsize()\n",
    "    for i in range(length):\n",
    "        if i == 0:\n",
    "            feature_tmp = feature_queue.get()\n",
    "            feature_queue.put(feature_tmp)\n",
    "            features = feature_tmp\n",
    "            feature_to_use = feature_tmp\n",
    "        else:\n",
    "            feature_tmp = feature_queue.get()\n",
    "            feature_queue.put(feature_tmp)\n",
    "            features = np.concatenate((features, feature_tmp), axis=0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_conv = VGG_conv().to(device)\n",
    "# vgg_conv.cuda()\n",
    "vgg_fc = VGG_fc().to(device)\n",
    "# vgg_fc.cuda()\n",
    "\n",
    "isomap_feature = torch.empty((BATCH_SIZE, n_dimentions), requires_grad=True, device=device)\n",
    "cost1 = tnn.MSELoss()\n",
    "cost2 = tnn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.Adam(vgg_conv.parameters(), lr=LEARNING_RATE)\n",
    "optimizer2 = torch.optim.Adam([{'params':vgg_fc.parameters()}\n",
    "                               ,{'params':isomap_feature}\n",
    "                              ], lr=LEARNING_RATE)\n",
    "back_tool = LocallyLinearBackward(n_neighbors=n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.cuda.FloatTensor'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isomap_feature.is_cuda\n",
    "isomap_feature.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 9.62 MiB (GPU 0; 11.93 GiB total capacity; 4.10 GiB already allocated; 3.06 MiB free; 11.47 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-bcfd83b893e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#     optimizer2.zero_grad()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0moutputs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#卷积网络的输出，将图片embedding成512维向量，the shape of output is (batch_size, 512)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_vec_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-52f2f94829fb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1621\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1622\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m     )\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 9.62 MiB (GPU 0; 11.93 GiB total capacity; 4.10 GiB already allocated; 3.06 MiB free; 11.47 MiB cached)"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(EPOCH):\n",
    "#  for i, (images, labels) in enumerate(trainLoader):\n",
    "  vgg_conv.train()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "#   train_img_queue = queue.Queue(maxsize=1000/BATCH_SIZE)    #构建输入图像的队列\n",
    "#   train_label_queue = queue.Queue(maxsize=1000/BATCH_SIZE) #构建label的队列\n",
    "  train_vec_queue = queue.Queue(maxsize=1000/BATCH_SIZE)    #构建卷积网络输出向量的队列\n",
    "  for images, labels in trainLoader:\n",
    "#     train_img_queue.put(images)\n",
    "#     train_label_queue.put(labels)\n",
    "    \n",
    "    # Forward + Backward + Optimize\n",
    "    \n",
    "#     optimizer1.zero_grad()\n",
    "#     optimizer2.zero_grad()\n",
    "\n",
    "    outputs1 = vgg_conv(images.to(device)) #卷积网络的输出，将图片embedding成512维向量，the shape of output is (batch_size, 512)\n",
    "    \n",
    "    train_vec_queue.put(outputs1)\n",
    "    \n",
    "#     print(train_vec_queue.qsize())\n",
    "#     print(train_vec_queue.get_nowait().shape)\n",
    "    \n",
    "    if train_img_queue.full():  #等队列满了之后，开始让所有图片进入isomap，然后pop出队首的数据进行反向传播\n",
    "        train_features = get_queue_elements(train_vec_queue) # type torch.tensor\n",
    "        \n",
    "#         feature_to_use = train_features[:BATCH_SIZE]\n",
    "        isomap_forward = isomap(train_features, n_components=32)#将1000张图片通过卷积层得到的embedding向量输入isomap层，获得降维后的结果\n",
    "                                                                    # type torch.tensor\n",
    "        batch_feature = isomap_forward[:BATCH_SIZE].float()\n",
    "        \n",
    "        img_tmp = train_img_queue.get()\n",
    "        label_tmp = train_label_queue.get()\n",
    "        vec_tmp = train_vec_queue.get()\n",
    "        \n",
    "        isomap_feature = batch_feature\n",
    "        outputs = vgg_fc(isomap_feature)\n",
    "        \n",
    "        \n",
    "        loss2 = cost2(outputs, label_tmp.to(device))\n",
    "        \n",
    "        #---------------------------------------\n",
    "#         Y = isomap_feature.detach().cpu().numpy()\n",
    "    \n",
    "        optimizer2.zero_grad()\n",
    "        loss2.backward()\n",
    "        optimizer2.step()\n",
    "        \n",
    "        Y = isomap_forward.detach().cpu().numpy()\n",
    "        Y_hat = isomap_feature.detach().cpu().numpy()\n",
    "        \n",
    "        if (np.any(np.isnan(Y))):\n",
    "            print(\"Nan element in Y\")\n",
    "            break\n",
    "        if( not np.all(np.isfinite(Y))):\n",
    "            print(\"Infinit element in Y\")\n",
    "            break\n",
    "            \n",
    "        back = LocallyLinearBackward(n_neighbors=10) # n_neighbors is a hyperparameter\n",
    "        back.fit(Y, Y_hat)\n",
    "        \n",
    "        X_hat = back.error_backward(vec_tmp.detach().cpu().numpy())\n",
    "        target = torch.from_numpy(X_hat).to(device)\n",
    "        loss1 = cost1(vec_tmp, target)\n",
    "        \n",
    "        optimizer1.zero_grad()\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "        #----------------------------------------\n",
    "#         current_img = train_img_queue.get()\n",
    "#         current_label = train_label_queue.get()\n",
    "#         current_vec = train_vec_queue.get()\n",
    "        \n",
    "    \n",
    "    \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "#     loss = cost(outputs, labels.cuda())\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "  print ('Epoch [%d/%d], Loss. %.4f' %\n",
    "             (epoch+1, EPOCH, loss.data[0]))\n",
    "  print('Test Accuracy of the model on the training set: %d %%' % (100 * correct / total))\n",
    "\n",
    "# # Test the model\n",
    "#   vgg16.eval()\n",
    "#   correct = 0\n",
    "#   total = 0\n",
    "\n",
    "#   for images, labels in testLoader:\n",
    "#     images = Variable(images).cuda()\n",
    "#     outputs = vgg16(images)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     total += labels.size(0)\n",
    "#     correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "#   print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "# # Save the Trained Model\n",
    "# torch.save(vgg16.state_dict(),'checkpoint_without_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backward use time: 0.042298\n",
      "backward use time: 0.043172\n",
      "backward use time: 0.074420\n",
      "backward use time: 0.061149\n",
      "backward use time: 0.053147\n",
      "backward use time: 0.060358\n",
      "backward use time: 0.047945\n",
      "backward use time: 0.038147\n",
      "backward use time: 0.052690\n",
      "backward use time: 0.038536\n",
      "backward use time: 0.061477\n",
      "backward use time: 0.079262\n",
      "backward use time: 0.043253\n",
      "backward use time: 0.035550\n",
      "backward use time: 0.061698\n",
      "backward use time: 0.051023\n",
      "backward use time: 0.076821\n",
      "backward use time: 0.045864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DB/rhome/yanghengzhao/miniconda3/envs/torch/lib/python3.6/site-packages/sklearn/decomposition/kernel_pca.py:278: RuntimeWarning: invalid value encountered in sqrt\n",
      "  X_transformed = self.alphas_ * np.sqrt(self.lambdas_)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-f3a27fef537a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mback_tool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mX_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mback_tool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/DATA5_DB8/data/yanghengzhao/iso_map/locally_linear.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, Y, Y_hat, return_error)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples_to_use\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocally_linear_backward_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mreturn_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/DATA5_DB8/data/yanghengzhao/iso_map/locally_linear.py\u001b[0m in \u001b[0;36mlocally_linear_backward_parameters\u001b[0;34m(Y, Y_hat, n_neighbors, method, reg, n_jobs)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'standard'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbarycenter_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'%s' is not a valid key word\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/DATA5_DB8/data/yanghengzhao/iso_map/locally_linear.py\u001b[0m in \u001b[0;36mbarycenter_weights\u001b[0;34m(X, Z, reg)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0mdevelopers\u001b[0m \u001b[0mnote\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0minformation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \"\"\"\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 573\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    vgg_conv.train()\n",
    "    vgg_fc.train()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    train_vec_queue = queue.Queue(maxsize=1000/BATCH_SIZE)\n",
    "    \n",
    "    for images, labels in trainLoader:\n",
    "        vec_output = vgg_conv(images.to(device)) # torch.tensor\n",
    "        \n",
    "        train_vec_queue.put(vec_output.detach().cpu().numpy()) # queue 中保存 numpy 变量\n",
    "        \n",
    "        if train_vec_queue.full():\n",
    "            train_vec_queue.get()\n",
    "            train_features = get_queue_elements(train_vec_queue) # np.float\n",
    "            \n",
    "            isomap_forward = isomap(train_features, n_components=n_dimentions) # np.float\n",
    "            \n",
    "            batch_feature = isomap_forward[-BATCH_SIZE:] # 取最后的BATCH_SIZE个用于训练\n",
    "            \n",
    "            isomap_feature.data -= isomap_feature.data + torch.from_numpy(batch_feature).float().to(device) # 保持tensor对象不变，只改变值\n",
    "            \n",
    "            outputs = vgg_fc(isomap_feature)\n",
    "            \n",
    "            #---------\n",
    "            loss2 = cost2(outputs, labels.to(device))\n",
    "            \n",
    "            optimizer2.zero_grad()\n",
    "            loss2.backward()\n",
    "            optimizer2.step()\n",
    "            #---------\n",
    "            # 误差前向传播\n",
    "            Y = isomap_forward\n",
    "            Y_hat = isomap_feature.data.cpu().numpy()\n",
    "            X = train_features\n",
    "            \n",
    "            start = time.time()\n",
    "            back_tool.fit(Y, Y_hat)\n",
    "            \n",
    "            X_hat = back_tool.error_backward(X)\n",
    "            end = time.time()\n",
    "            print(\"backward use time: %f\" %(end-start))\n",
    "            target = torch.from_numpy(X_hat).to(device)\n",
    "            \n",
    "            #----------\n",
    "            loss1 = cost1(vec_output, target)\n",
    "            optimizer1.zero_grad()\n",
    "            loss1.backward()\n",
    "            optimizer1.step()\n",
    "            #----------\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "        \n",
    "    print ('Epoch [%d/%d], Loss. %.4f' %\n",
    "             (epoch+1, EPOCH, loss.data[0]))\n",
    "    print('Test Accuracy of the model on the training set: %d %%' % (100 * correct / total))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel = VGG_fc()\n",
    "# input dimention = 32\n",
    "Input = torch.ones(50,32)\n",
    "Input.requires_grad = True\n",
    "optimizer = torch.optim.Adam([{'params':testModel.parameters()},\n",
    "                           {'params':Input}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = testModel(Input)\n",
    "\n",
    "cost = tnn.CrossEntropyLoss()\n",
    "loss = cost(output, torch.ones(50).long())\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0011, -0.0017,  0.0018,  ...,  0.0016,  0.0015,  0.0004],\n",
       "        [-0.0011, -0.0017,  0.0018,  ...,  0.0016,  0.0015,  0.0004],\n",
       "        [-0.0011, -0.0017,  0.0018,  ...,  0.0016,  0.0015,  0.0004],\n",
       "        ...,\n",
       "        [-0.0011, -0.0017,  0.0018,  ...,  0.0016,  0.0015,  0.0004],\n",
       "        [-0.0011, -0.0017,  0.0018,  ...,  0.0016,  0.0015,  0.0004],\n",
       "        [-0.0011, -0.0017,  0.0018,  ...,  0.0016,  0.0015,  0.0004]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input = Input *0 + torch.ones((50,32))\n",
    "Input.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input = torch.from_numpy(np.ones((50,32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.empty((5,10),requires_grad=True)\n",
    "I = torch.ones((10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.ones((5,10), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = x.mm(I)\n",
    "loss = torch.sum(tmp)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(t)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3630e-36,  4.5775e-41, -3.5093e-34,  4.5775e-41,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00, -3.8761e-34,  4.5775e-41],\n",
       "        [-3.8761e-34,  4.5775e-41, -3.8761e-34,  4.5775e-41,  0.0000e+00,\n",
       "          0.0000e+00,  4.2964e+24,  1.0765e+21,  7.9050e+31,  5.5515e-08],\n",
       "        [ 1.3882e+31,  1.3043e-11,  2.7489e+26,  1.8175e+31, -3.8761e-34,\n",
       "          4.5775e-41, -3.8761e-34,  4.5775e-41, -3.8761e-34,  4.5775e-41],\n",
       "        [ 1.4013e-45,  0.0000e+00, -3.5094e-34,  4.5775e-41, -6.0348e+22,\n",
       "          4.5775e-41, -3.1804e-34,  4.5775e-41, -5.8122e+22,  4.5775e-41],\n",
       "        [ 2.1019e-44,  0.0000e+00,  1.4013e-45,  0.0000e+00,  3.6869e+24,\n",
       "          4.5775e-41,  3.6154e-43,  4.5559e-41,  2.9147e-43,  0.0000e+00]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140105861432592\n",
      "140105861432592\n",
      "140105861432592\n"
     ]
    }
   ],
   "source": [
    "print(id(x.data))\n",
    "x.data = torch.from_numpy(t)\n",
    "print(id(x.data))\n",
    "x = torch.from_numpy(t)\n",
    "print(id(x))\n",
    "# x = x -1\n",
    "# print(id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 10), dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
